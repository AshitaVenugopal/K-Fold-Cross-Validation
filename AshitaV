#Install requisite packages
install.packages("gmodels")
install.packages("Hmisc")
install.packages("pROC")
install.packages("ResourceSelection")
install.packages("car")
install.packages("caret")
install.packages("dplyr")
install.packages("DAAG")
install.packages("titanic")
install.packages("rpart.plot")
install.packages("randomForest")
install.packages("DAAG")
library(titanic)
library(rpart.plot)
library(InformationValue)
library(rpart)
library(randomForest)
library("DAAG")
library(gmodels)
library(Hmisc)
library(pROC)
library(ResourceSelection)
library(car)
library(caret)
library(dplyr)

# Call the data from the address path
df.titanic_main <- read.csv('Put path here')
str(df.titanic_main)

#Placing mean age in blanks
df.titanic_main$Age[is.na(df.titanic_main$Age)] <- round(mean(df.titanic_main$Age, na.rm = TRUE))
summary(df.titanic_main) 


# Split the data into training and test
set.seed(1234) # for reproducibility
df.titanic_main$rand <- runif(nrow(df.titanic_main))
df.train <- df.titanic_main[df.titanic_main$rand <= 0.7,]
df.test <- df.titanic_main[df.titanic_main$rand > 0.7,]
nrow(df.train)
nrow(df.test)


CrossTable(df.titanic_main$Survived)
CrossTable(df.train$Survived)
CrossTable(df.test$Survived)

#Build a model using the training data , Logistic regression
titanic_model <- glm(formula = Survived ~ Pclass + Sex + SibSp + Parch + Fare + Age,
                     data=df.train, family = binomial)

titanic_lm <- lm(formula = Survived ~ Pclass + Sex + SibSp + Parch + Fare + Age,
                     data=df.train) 

#To remove insignificant variables
vif(titanic_lm)
summary(titanic_lm)

#Remove Parch, create model again
df.train$Parch <- NULL

titanic_model <- glm(formula = Survived ~ Pclass + Sex + SibSp + Fare + Age,
                     data=df.train, family = binomial)
summary(titanic_model)


#Remove Fare, create model again
df.train$Fare <- NULL
titanic_model <- glm(formula = Survived ~ Pclass + Sex + SibSp + Age,
                     data=df.train, family = binomial)
summary(titanic_model)

#No more insignificant variables

#First test model again on training set
df.train$prob = predict(titanic_model, newdata = df.train,  type=c("response"))
df.train$spred <- ifelse(df.train$prob>=.5,'pred_yes','pred_no')
table(df.train$spred,df.train$Survived)


#Model is ready to be tested in test set

df.test$prob = predict(titanic_model, newdata = df.test,  type=c("response"))
df.test$spred <- ifelse(df.test$prob>=.5,'pred_yes','pred_no')
table(df.test$spred,df.test$Survived)


#K-fold cross validation
?`function-class`

KFold <- function(ds_name,equation,regr_type,k)
{
  obj <- glm(formula = equation, data = ds_name, family = regr_type )
  CVbinary(obj, nfolds= k, print.details=TRUE)
  
}

MSE_func <- function(ds_name,equation)
{
  LM <- lm(formula=equation, data=ds_name)
  LM_sum <-summary(LM)
  MSE <- mean(LM_sum$residuals^2)
  print("Mean squared error")
  print(MSE)
}

#Calling the KFold function for training data
Train_obj <- KFold(df.train, Survived ~ Pclass + Sex + SibSp + Age, binomial , 10)

#Calling the Mean Squared Error function for training data
Train_MSE <-MSE_func(df.train,Survived ~ Pclass + Sex + SibSp + Age)

#confusion matrix on training set
table(df.train$Survived,round(Train_obj$cvhat))
print("Estimate of Accuracy")
print(Train_obj$acc.cv)

#Calling the KFold function for test data
Test_obj <- KFold(df.test,Survived ~ Pclass + Sex + SibSp + Age,binomial,10)

#Calling the Mean Squared Error function for test data
Test_MSE <-MSE_func(df.test,Survived ~ Pclass + Sex + SibSp + Age)

#Confusion matrix for test set
table(df.test$Survived,round(Test_obj$cvhat))
print("Estimate of Accuracy")
print(Test_obj$acc.cv)
